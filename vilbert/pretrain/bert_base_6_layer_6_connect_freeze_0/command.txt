Namespace(baseline=False, bert_model='bert-base-uncased', config_file='config/bert_base_6layer_6conect.json', distributed=False, do_lower_case=True, fp16=False, freeze=-1, from_pretrained='bert-base-uncased', gradient_accumulation_steps=1, img_weight=1, learning_rate=0.0001, local_rank=-1, loss_scale=0, max_seq_length=36, no_cuda=False, num_train_epochs=10.0, num_workers=16, on_memory=False, output_dir='save', predict_feature=False, save_name='bert_base_6_layer_6_connect_freeze_0', seed=42, start_epoch=0, train_batch_size=512, train_file='data/conceptual_caption/training', use_chuncks=0, validation_file='data/conceptual_caption/validation', warmup_proportion=0.1)


{
  "attention_probs_dropout_prob": 0.1,
  "bi_attention_type": 1,
  "bi_hidden_size": 1024,
  "bi_intermediate_size": 1024,
  "bi_num_attention_heads": 8,
  "fast_mode": false,
  "fixed_t_layer": 0,
  "fixed_v_layer": 0,
  "fusion_method": "mul",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "in_batch_pairs": false,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "intra_gate": false,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooling_method": "mul",
  "predict_feature": false,
  "t_biattention_id": [
    6,
    7,
    8,
    9,
    10,
    11
  ],
  "type_vocab_size": 2,
  "v_attention_probs_dropout_prob": 0.1,
  "v_biattention_id": [
    0,
    1,
    2,
    3,
    4,
    5
  ],
  "v_feature_size": 2048,
  "v_hidden_act": "gelu",
  "v_hidden_dropout_prob": 0.1,
  "v_hidden_size": 1024,
  "v_initializer_range": 0.02,
  "v_intermediate_size": 1024,
  "v_num_attention_heads": 8,
  "v_num_hidden_layers": 6,
  "v_target_size": 1601,
  "vocab_size": 30522
}

